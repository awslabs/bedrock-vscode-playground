/* eslint-disable @typescript-eslint/naming-convention */
export const titanTextExpressModelCard = `
<p> AI and ML have been a focus for Amazon for over 20 years, and many of the capabilities customers use with Amazon are driven by ML. Amazon Titan models are built by leveraging Amazon’s decades of experience to make ML accessible to anyone who wants to use it. </p>

<p> Amazon Titan Foundation Models are pre-trained on large datasets, making them powerful, general-purpose models. Use them as is, or customize them by fine tuning the models with your own data for a particular task without annotating large volumes of data.</p>

<p> Titan Text Generation 1 (G1) - Express is a generative large language model (LLM) for tasks such as summarization, text generation (for example, creating a blog post), classification, open-ended Q&A, and information extraction.

    <ul>
        <li> Version: 1 </li>
        <li> Max tokens: 8k </li>
        <li> Languages: English </li>
        <li> Supported formats: Open ended text generation, brainstorming, summarization, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, Q&A, chat </li>
        <li> Model attributes: Text generation, Code generation, Instruction following </li>
    </ul>
</p>
`;

export const titanTextLiteModelCard = `
<p> AI and ML have been a focus for Amazon for over 20 years, and many of the capabilities customers use with Amazon are driven by ML. Amazon Titan models are built by leveraging Amazon’s decades of experience to make ML accessible to anyone who wants to use it. </p>

<p> Amazon Titan Foundation Models are pre-trained on large datasets, making them powerful, general-purpose models. Use them as is, or customize them by fine tuning the models with your own data for a particular task without annotating large volumes of data.</p>

<p> Titan Text Generation 1 (G1) - Lite is a generative large language model (LLM) for tasks such as summarization, text generation (for example, creating a blog post), classification, open-ended Q&A, and information extraction.

    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 4k </li>
        <li> Languages: English </li>
        <li> Supported formats: Open ended text generation, brainstorming, summarization, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, Q&A, chat </li>
        <li> Model attributes: Text generation, Code generation, Instruction following </li>
    </ul>
</p>
`;

export const titanTextPremierModelCard = `
<p> AI and ML have been a focus for Amazon for over 20 years, and many of the capabilities customers use with Amazon are driven by ML. Amazon Titan models are built by leveraging Amazon’s decades of experience to make ML accessible to anyone who wants to use it. </p>

<p> Amazon Titan Foundation Models are pre-trained on large datasets, making them powerful, general-purpose models. Use them as is, or customize them by fine tuning the models with your own data for a particular task without annotating large volumes of data.</p>

<p> Titan Text Premier is a powerful and advanced model within the Titan Text family, designed to deliver superior performance across a wide range of enterprise applications. With its cutting-edge capabilities, it offers enhanced accuracy and exceptional results, making it an excellent choice for organizations seeking top-notch text processing solutions.

    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 32k </li>
        <li> Languages: English </li>
        <li> Supported formats: Open-ended text generation, brainstorming, summarization, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, Q&A, retrieval-augmented generation (RAG), and chat. </li>
        <li> Model attributes: Text generation, Code generation, Instruction following </li>
    </ul>
</p>
`;

export const claude_2_ModelCard = `
<p> Anthropic's most powerful model, which excels at a wide range of tasks from sophisticated dialogue and creative content generation to detailed instruction following.
    <ul>
        <li> Version: 2.0 </li>
        <li> Max tokens: 100k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: Question answering, information extraction, removing PII, content generation, multiple choice classification, Roleplay, comparing text, summarization, document Q&A with citation </li>
        <li> Model attributes: Text generation, Conversational </li>
    </ul>
</p>
`;

export const claude_2_1_ModelCard = `
<p> An update to Claude 2 that features double the context window, plus improvements across reliability, hallucination rates, and evidence-based accuracy in long document and RAG contexts.
    <ul>
        <li> Version: 2.1 </li>
        <li> Max tokens: 200k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: Question answering, information extraction, removing PII, content generation, multiple choice classification, Roleplay, comparing text, summarization, document Q&A with citation </li>
        <li> Model attributes: Text generation, Conversation, Complex reasoning & analysis </li>
    </ul>
</p>
`;

export const claude_3_Sonnet_ModelCard = `
<p> Claude 3 Sonnet by Anthropic strikes the ideal balance between intelligence and speed—particularly for enterprise workloads. It offers maximum utility at a lower price than competitors, and is engineered to be the dependable, high-endurance workhorse for scaled AI deployments. Claude 3 Sonnet can process images and return text outputs, and features a 200K context window.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 200k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: RAG or search & retrieval over vast amounts of knowledge, product recommendations, forecasting, targeted marketing, code generation, quality control, parse text from images </li>
        <li> Model attributes: Image to text & code, multilingual conversation, complex reasoning & analysis </li>
    </ul>
</p>
`;

export const claude_3_Haiku_ModelCard = `
<p> Claude 3 Haiku is Anthropic's fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with speed. Customers will be able to build seamless AI experiences that mimic human interactions. Claude 3 Haiku can process images and return text outputs, and features a 200K context window.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 200k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: 1/ Customer interactions: quick and accurate support in live interactions, translations 2/ Content moderation: catch risky behavior or customer requests 3/ Cost-saving tasks: optimized logistics, inventory management, extract knowledge from unstructured data </li>
        <li> Model attributes: Image to text, conversation, chat optimized </li>
    </ul>
</p>
`

export const claude_3_Opus_ModelCard = `
<p> Claude 3 Opus is Anthropic's most powerful AI model, with state-of-the-art performance on highly complex tasks. It can navigate open-ended prompts and sight-unseen scenarios with remarkable fluency and human-like understanding. Claude 3 Opus shows us the frontier of what’s possible with generative AI. Claude 3 Opus can process images and return text outputs, and features a 200K context window.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 200k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: 1/ Task automation: plan and execute complex actions across APIs and databases, interactive coding 2/ R&D: research review, brainstorming and hypothesis generation, drug discovery 3/ Strategy: advanced analysis of charts & graphs, financials and market trends, forecasting </li>
        <li> Model attributes: Image to text & code, multilingual conversation, complex reasoning & analysis </li>
    </ul>
</p>
`

export const claudeInstantModelCard = `
<p> A faster and cheaper yet still very capable model, which can handle a range of tasks including casual dialogue, text analysis, summarization, and document question-answering.
    <ul>
        <li> Version: 1.2 </li>
        <li> Max tokens: 100k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: Question answering, information extraction, removing PII, content generation, multiple choice classification, Roleplay, comparing text, summarization, document Q&A with citation </li>
        <li> Model attributes: Text generation, Conversational </li>
    </ul>
</p>
`;

export const commandModelCard = `

<p> Command is a text generation model for business use cases. Command is trained on data that supports reliable business applications, like text generation, summarization, copywriting, dialogue, extraction, and question answering.
    <ul>
        <li> Version: 14.7 </li>
        <li> Max tokens: 4096 </li>
        <li> Languages: English </li>
        <li> Supported use cases: Summarization, copywriting, dialogue, extraction, and question answering. </li>
        <li> Model attributes: Text generation, Instruction following </li>
    </ul>
</p>
`;

export const commandLightModelCard = `

<p> Cohere's Command-Light is a generative model that responds well with instruction-like prompts. This model provides customers with an unbeatable balance of quality, cost-effectiveness, and low-latency inference.
    <ul>
        <li> Version: 14.7 </li>
        <li> Max tokens: 4000 </li>
        <li> Languages: English </li>
        <li> Supported use cases: Summarization, copywriting, dialogue, extraction, and question answering. </li>
        <li> Model attributes: Text generation, Instruction following </li>
    </ul>
</p>
`;

export const jurassicUltraModelCard = `
<p> Jurassic-2 Ultra is AI21’s most powerful model offering exceptional quality. Apply Jurassic-2 Ultra to complex tasks that require advanced text generation and comprehension. Popular use cases include question answering, summarization, long-form copy generation, advanced information extraction, and more.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 8191 </li>
        <li> Languages: English, Spanish, French, German, Portuguese, Italian, Dutch </li>
        <li> Supported use cases: Open book question answering, summarization, draft generation, information extraction, ideation </li>
        <li> Model attributes: Text, Classification, Insert/edit </li>
    </ul>
</p>
`;

export const jurassicMidModelCard = `
<p> Jurassic-2 Mid is AI21’s mid-sized model, carefully designed to strike the right balance between exceptional quality and affordability. Jurassic-2 Mid can be applied to any language comprehension or generation task including question answering, summarization, long-form copy generation, advanced information extraction and many others.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 8191 </li>
        <li> Languages: English, Spanish, French, German, Portuguese, Italian, Dutch </li>
        <li> Supported use cases: Open book question answering, summarization, draft generation, information extraction, ideation </li>
        <li> Model attributes: Text, Classification, Insert/edit, Math </li>
    </ul>
</p>
`;

export const llama_2_ModelCard = `
<p> A dialogue use case optimized variant of Llama 2 models. Llama 2 is an auto-regressive language model that uses an optimized transformer architecture. Llama 2 is intended for commercial and research use in English.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 4096 </li>
        <li> Languages: English </li>
        <li> Supported use cases: Llama 2 is intended for commercial and research use in English. Fine-tuned chat models are intended for chat based applications. </li>
        <li> Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in any other way that is prohibited by the Acceptable Use Policy and Llama 2 Community License. </li>
        <li> Model attributes: Text generation, Chat optimized, Conversational </li>
    </ul>
</p>
`;

export const llama_3_ModelCard = `
<p> Meta Llama 3 is an accessible, open large language model (LLM) designed for developers, researchers, and businesses to build, experiment, and responsibly scale their generative AI ideas. Part of a foundational system, it serves as a bedrock for innovation in the global community. Ideal for limited computational power and resources, edge devices, and faster training times.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 8000 </li>
        <li> Languages: English </li>
        <li> Supported use cases: Llama 3 is intended for commercial and research use in English. Fine-tuned chat models are intended for chat based applications. </li>
        <li> Model attributes: Text summarization, Text classification, Sentiment analysis, Language modeling, Dialog systems, Code generation, Following instructions, Sentiment analysis with nuances in reasoning, Text classification with improved accuracy and nuance, Text summarization with accuracy and nuance </li>
    </ul>
</p>
`;

export const mistral_7b_Instruct_ModelCard = `
<p> A 7B dense Transformer, fast-deployed and easily customisable. Small, yet powerful for a variety of use cases. Supports English and code, and a 32k context window.
    <ul>
        <li> Version: 0.2 </li>
        <li> Max tokens: 32K </li>
        <li> Languages: English </li>
        <li> Supported use cases: Variety </li>
        <li> Model attributes: Classification, Text generation, Code generation </li>
    </ul>
</p>
`;

export const mistral_8x7b_Instruct_ModelCard = `
<p> A 7B sparse Mixture-of-Experts model with stronger capabilities than Mistral 7B. Uses 12B active parameters out of 45B total. Supports multiple languages, code and 32k context window.
    <ul>
        <li> Version: 0.1 </li>
        <li> Max tokens: 32K </li>
        <li> Languages: English </li>
        <li> Supported use cases: Variety </li>
        <li> Model attributes: Complex reasoning & analysis, Text generation, Code generation </li>
    </ul>
</p>
`;

export const mistral_Large_ModelCard = `
<p> The most advanced Mistral AI Large Language model capable of handling any language task including complex multilingual reasoning, text understanding, transformation, and code generation.
    <ul>
        <li> Version: 2402 </li>
        <li> Max tokens: 32K </li>
        <li> Languages: English, French, Italian, German and Spanish</li>
        <li> Supported use cases: Variety </li>
        <li> Model attributes: Complex reasoning & analysis, Text generation, Code generation, RAG, Agents </li>
    </ul>
</p>
`;

export const mistral_Small_ModelCard = `
<p> Mistral Small is perfectly suited for straightforward tasks that can be performed in bulk, such as classification, customer support, or text generation. It provides outstanding performance at a cost-effective price point.
    <ul>
        <li> Version: 2402 </li>
        <li> Max tokens: 32K </li>
        <li> Languages: English, French, Italian, German and Spanish</li>
        <li> Supported use cases: Variety </li>
        <li> Model attributes: Text generation, Code generation, Classification, RAG, Conversation </li>
    </ul>
</p>
`;

export const mistral_Large_2_ModelCard = `
<p> The most advanced Mistral AI Large Language model capable of handling any language task including complex multilingual reasoning, text understanding, transformation, and code generation.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 128K </li>
        <li> Languages: English, French, Italian, German and Spanish</li>
        <li> Supported use cases: Variety </li>
        <li> Model attributes: Complex reasoning & analysis, Text generation, Code generation, RAG, Agents </li>
    </ul>
</p>
`;

export const llama_3_1_ModelCard = `
<p> The Llama 3.1 offering of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 8B, 70B and 405B sizes (text in/text out). The Llama 3.1 instruction-tuned text only models (8B, 70B, 405B) are optimized for multilingual dialogue use cases and outperform many of the available open source chat models on common industry benchmarks. Llama 3.1 is intended for commercial and research use in multiple languages. Instruction tuned text only models are intended for assistant-like chat, whereas pretrained models can be adapted for a variety of natural language generation tasks. The Llama 3.1 models also support the ability to leverage the outputs of its models to improve other models including synthetic data generation and distillation. Llama 3.1 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 128k </li>
        <li> Languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai </li>
        <li> Supported use cases: Input modalities: multilingual text; Output modalities: multilingual text and code </li>
        <li> Model attributes: Ability to follow instructions and tasks, improved reasoning and understanding of nuances and context, and multilingual translation. </li>
    </ul>
</p>
`;

export const jurassicJambaModelCard = `
<p> The latest Foundation Model from AI21 Labs, Jamba-Instruct offers an impressive 256K context window and delivers the best value per price on core text generation, summarization, and question answering tasks for the enterprise.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 256k </li>
        <li> Languages: English </li>
        <li> Supported use cases: Customer chatbot, internal agent assist, lengthy document summarization </li>
        <li> Model attributes: Text generation, Document summarization, Question answering </li>
    </ul>
</p>
`;

export const claude_3_5_Sonnet_ModelCard = `
<p> Claude 3.5 Sonnet by Anthropic strikes the ideal balance between intelligence and speed—particularly for enterprise workloads. It offers maximum utility at a lower price than competitors, and is engineered to be the dependable, high-endurance workhorse for scaled AI deployments. Claude 3.5 Sonnet can process images and return text outputs, and features a 200K context window.
    <ul>
        <li> Version: 1.0 </li>
        <li> Max tokens: 200k </li>
        <li> Languages: Multilingual </li>
        <li> Supported use cases: RAG or search & retrieval over vast amounts of knowledge, product recommendations, forecasting, targeted marketing, code generation, quality control, parse text from images </li>
        <li> Model attributes: Image to text & code, multilingual conversation, complex reasoning & analysis </li>
    </ul>
</p>
`;