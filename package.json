{
  "name": "bedrock-vscode-playground",
  "displayName": "Bedrock Visual Studio Code Playground",
  "description": "Explore and experiment with large language models (LLMs) available in Amazon Bedrock",
  "version": "0.7.0",
  "publisher": "AmazonWebServices-AISolutionsArchitecture",
  "engines": {
    "vscode": "^1.82.0"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/awslabs/bedrock-vscode-playground"
  },
  "icon": "media/bedrock-vscode-playground.png",
  "keywords": [
    "llm",
    "bedrock",
    "code",
    "ai",
    "code-referencing",
    "documentation",
    "refactor",
    "typescript"
  ],
  "categories": [
    "Programming Languages",
    "Machine Learning",
    "Education"
  ],
  "activationEvents": [],
  "main": "./dist/extension.js",
  "configuration": {
    "title": "GitMagic"
  },
  "contributes": {
    "configuration": {
      "title": "Bedrock Playground",
      "properties": {
        "bedrockPlayground.profileName": {
          "type": "string",
          "default": "default",
          "markdownDescription": "AWS profile used to invoke the Amazon Bedrock service. If profile name is not provided or invalid, then the `default` profile is used."
        },
        "bedrockPlayground.region": {
          "type": "string",
          "default": "us-west-2",
          "markdownDescription": "The AWS region to send requests to."
        },
        "bedrockPlayground.generate.modelId": {
          "type": "string",
          "default": "anthropic.claude-v2:1",
          "enum": [
            "anthropic.claude-3-sonnet-20240229-v1:0",
            "anthropic.claude-3-haiku-20240307-v1:0",
            "anthropic.claude-v2:1",
            "anthropic.claude-v2",
            "anthropic.claude-instant-v1",
            "cohere.command-text-v14",
            "cohere.command-light-text-v14",
            "ai21.j2-ultra-v1",
            "ai21.j2-mid-v1",
            "amazon.titan-text-express-v1",
            "amazon.titan-text-lite-v1",
            "amazon.titan-text-premier-v1:0",
            "meta.llama2-13b-chat-v1",
            "meta.llama2-70b-chat-v1",
            "mistral.mistral-7b-instruct-v0:2",
            "mistral.mixtral-8x7b-instruct-v0:1",
            "mistral.mistral-large-2402-v1:0",
            "mistral.mistral-small-2402-v1:0",
            "meta.llama3-8b-instruct-v1:0",
            "meta.llama3-70b-instruct-v1:0",
            "anthropic.claude-3-opus-20240229-v1:0",
            "anthropic.claude-3-5-sonnet-20240620-v1:0",
            "meta.llama3-1-8b-instruct-v1:0",
            "meta.llama3-1-70b-instruct-v1:0",
            "meta.llama3-1-405b-instruct-v1:0",
            "ai21.jamba-instruct-v1:0",
            "mistral.mistral-large-2407-v1:0"
          ],
          "markdownDescription": "The default model for to use for `Bedrock Playground: Generate` command."
        },
        "bedrockPlayground.generate.promptTemplates": {
          "type": "object",
          "default": {
            "generate": "\n\nHuman: {REQUEST}\nPlease placed your response in <response></response> XML tags.\n\nAssistant:",
            "generateWithContext": "\n\nHuman: Use the context wrapped in <context></context> tags to respond to a user's request.\nThe user's request will be wrapped in <request></request> tags.\n<context>{CONTEXT}</context>\n<request>{REQUEST}</request>\nPlease place your response in <response></response> tags.\n\nAssistant:"
          },
          "markdownDescription": "The prompt templates used when invoking `Bedrock Playground: Generate`. Each template must contain a `{REQUEST}` placeholder which will be substituted with the user's request. The `generateWithContext` template should also contain a `{CONTEXT}` placeholder, which will be substituted with context from a file."
        },
        "bedrockPlayground.inferenceParameters.anthropicClaude": {
          "type": "object",
          "default": {
            "max_tokens": 500,
            "anthropic_version": "bedrock-2023-05-31",
            "system": "",
            "temperature": 0.5,
            "top_k": 250,
            "top_p": 1,
            "stop_sequences": [
            ]
          },
          "markdownDescription": "[Inference parameters for Anthropic Claude models.](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html#model-parameters-anthropic-claude-messages-request-response)"
        },
        "bedrockPlayground.inferenceParameters.AI21 Jurassic-2": {
          "type": "object",
          "default": {
            "temperature": 0.5,
            "topP": 0.5,
            "maxTokens": 200,
            "stopSequences": [],
            "countPenalty": {
              "scale": 0,
              "applyToWhitespaces": false,
              "applyToPunctuations": false,
              "applyToNumbers": false,
              "applyToStopwords": false,
              "applyToEmojis": false
            },
            "presencePenalty": {
              "scale": 0,
              "applyToWhitespaces": false,
              "applyToPunctuations": false,
              "applyToNumbers": false,
              "applyToStopwords": false,
              "applyToEmojis": false
            },
            "frequencyPenalty": {
              "scale": 0,
              "applyToWhitespaces": false,
              "applyToPunctuations": false,
              "applyToNumbers": false,
              "applyToStopwords": false,
              "applyToEmojis": false
            }
          },
          "markdownDescription": "[Inference parameters for AI21 Jurassic-2 models.](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-jurassic2.html)"
        },
        "bedrockPlayground.inferenceParameters.AI21 Jamba-Instruct": {
          "type": "object",
          "default": {
            "temperature": 0.5,
            "top_p": 0.5,
            "max_tokens": 200,
            "stop": []
          },
          "markdownDescription": "[Inference parameters for AI21 Jamba-Instruct models.](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-jamba.html)"
        },
        "bedrockPlayground.inferenceParameters.amazonTitanText": {
          "type": "object",
          "default": {
            "temperature": 0,
            "topP": 1,
            "maxTokenCount": 512,
            "stopSequences": []
          },
          "markdownDescription": "[Inference parameters for Amazon Titan Text models.](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-text.html)"
        },
        "bedrockPlayground.inferenceParameters.cohereCommand": {
          "type": "object",
          "default": {
            "temperature": 0.9,
            "p": 0.75,
            "k": 0,
            "max_tokens": 20,
            "stop_sequences": [],
            "truncate": "END"
          },
          "markdownDescription": "[Inference parameters for Cohere Command models.](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-cohere-command.html)"
        },
        "bedrockPlayground.inferenceParameters.metaLlama2": {
          "type": "object",
          "default": {
            "temperature": 0.5,
            "top_p": 0.9,
            "max_gen_len": 512
          },
          "markdownDescription": "[Inference parameters for Meta Llama 2 models.](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-meta.html)"
        },
        "bedrockPlayground.inferenceParameters.mistral": {
          "type": "object",
          "default": {
            "max_tokens": 200,
            "temperature": 0.5,
            "top_p": 0.9,
            "top_k": 200 
          },
          "markdownDescription": "[Inference parameters for Mistral models.](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-mistral.html#model-parameters-mistral-request-response)"
        }
      }
    },
    "commands": [
      {
        "command": "bedrock.playground",
        "title": "Bedrock Playground: Open Playground"
      },
      {
        "command": "bedrock.generate",
        "title": "Bedrock Playground: Generate"
      }
    ]
  },
  "scripts": {
    "vscode:prepublish": "npm run package",
    "compile": "webpack",
    "watch": "webpack --watch",
    "package": "webpack --mode production --devtool hidden-source-map",
    "compile-tests": "tsc -p . --outDir out",
    "lint": "eslint src --ext ts",
    "unit-tests": "npm run compile-tests && vscode-test --label unitTests"
  },
  "devDependencies": {
    "@aws-sdk/types": "^3.451.0",
    "@types/chai": "^4.3.9",
    "@types/mocha": "^10.0.1",
    "@types/node": "16.x",
    "@types/sinon": "^10.0.20",
    "@types/sinon-chai": "^3.2.11",
    "@types/vscode": "^1.82.0",
    "@types/vscode-webview": "^1.57.0",
    "@typescript-eslint/eslint-plugin": "^6.4.1",
    "@typescript-eslint/parser": "^6.4.1",
    "@vscode/test-cli": "^0.0.3",
    "@vscode/test-electron": "^2.3.5",
    "aws-sdk-client-mock": "^3.0.0",
    "chai": "^4.3.10",
    "eslint": "^8.47.0",
    "glob": "^10.3.3",
    "mocha": "^10.2.0",
    "prettier": "^2.8.1",
    "sinon": "^16.1.3",
    "sinon-chai": "^3.7.0",
    "ts-loader": "^9.4.4",
    "typescript": "^5.1.6",
    "webpack": "^5.94.0",
    "webpack-cli": "^5.1.4"
  },
  "dependencies": {
    "@aws-sdk/client-bedrock": "^3.525.0",
    "@aws-sdk/client-bedrock-runtime": "^3.525.0",
    "@aws-sdk/credential-providers": "^3.525.0",
    "@aws-sdk/types": "^3.525.0",
    "@smithy/util-stream": "^2.0.20",
    "@vscode/webview-ui-toolkit": "^1.2.2"
  }
}